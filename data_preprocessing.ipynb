{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import PyQt5\n",
    "from PIL import Image\n",
    "from IPython.display import Video\n",
    "import nb_helpers\n",
    "import os\n",
    "import csv\n",
    "\n",
    "mp.drawings = mp.solutions.drawing_utils"
   ],
   "metadata": {
    "id": "V0S_3ej0rYD9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "outputId": "076b9bfb-03ec-4f9f-c22d-86fb6c05728b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Delete frames"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def delete_video_folders(base_path='data/users'):\n",
    "    \"\"\"Elimina tutte le cartelle che contengono i frame, comprese le cartelle con il nome del video.\"\"\"\n",
    "    for user in os.listdir(base_path):\n",
    "        videos_path = os.path.join(base_path, user, 'videos')\n",
    "\n",
    "        if not os.path.isdir(videos_path):  # Controlla che \"videos\" sia una cartella\n",
    "            continue  \n",
    "\n",
    "        for video_folder in os.listdir(videos_path):\n",
    "            video_folder_path = os.path.join(videos_path, video_folder)\n",
    "\n",
    "            # Se è una cartella (quindi una di quelle create per i frame), la eliminiamo\n",
    "            if os.path.isdir(video_folder_path):\n",
    "                shutil.rmtree(video_folder_path)\n",
    "                print(f\"Cartella eliminata: {video_folder_path}\")\n",
    "\n",
    "delete_video_folders()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract frame from video"
   ],
   "metadata": {
    "id": "emcH2alMk7lv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "base_path = 'data/users/d1cb40d5abd6da294762d26746e64ab7e10c379b'\n",
    "\n",
    "for user in os.listdir(base_path):\n",
    "    videos_path = os.path.join(base_path, 'videos')\n",
    "\n",
    "    if not os.path.isdir(videos_path):  # Controlla che \"videos\" sia una cartella\n",
    "        print(\"No folder\")\n",
    "        continue\n",
    "\n",
    "        # take only the first video\n",
    "    video = os.listdir(videos_path)[1]\n",
    "    video_path = os.path.join(videos_path, video)\n",
    "\n",
    "    if os.path.isfile(video_path) and video.endswith('.mp4'):  # Controlla che sia un file video\n",
    "        video_name = video.rsplit('.mp4', 1)[0]  # Rimuove .mp4 dal nome\n",
    "        frames_folder = os.path.join(base_path, user, 'frames', video_name)\n",
    "\n",
    "        os.makedirs(frames_folder, exist_ok=True)  # Crea la cartella per i frame all'interno di \"frames\"\n",
    "\n",
    "        # Apri il video con OpenCV\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # Esce quando il video finisce\n",
    "\n",
    "            frame_filename = os.path.join(frames_folder, f'frame_{frame_count:05d}.jpg')\n",
    "            cv2.imwrite(frame_filename, frame)  # Salva il frame\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()  # Chiude il file video\n",
    "\n",
    "        print(f\"Salvati {frame_count} frame in {frames_folder}\")\n",
    "\n",
    "    else:\n",
    "        print(video_path)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "w0SWJHUOkhCu",
    "outputId": "aba357e3-5b4f-48ef-8052-3134a3d2c1b8",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:21:25.720289Z",
     "start_time": "2025-04-01T11:21:23.748868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvati 122 frame in data/users/d1cb40d5abd6da294762d26746e64ab7e10c379b/videos/frames/d1cb40d5abd6da294762d26746e64ab7e10c379b_inquietanti_aa3d8e9f-7c1a-4a0e-be47-4a9766592c15.jpg\n",
      "Salvati 122 frame in data/users/d1cb40d5abd6da294762d26746e64ab7e10c379b/tensors/frames/d1cb40d5abd6da294762d26746e64ab7e10c379b_inquietanti_aa3d8e9f-7c1a-4a0e-be47-4a9766592c15.jpg\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": "Landmarks and RGB tensor",
   "metadata": {
    "id": "y4hlUshClG8-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Inizializza MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def process_frames_and_plot():\n",
    "    files = sorted(os.listdir('data/frames'))\n",
    "    num_frames = len(files)\n",
    "    landmark_tensor = np.zeros((num_frames, 478, 3), dtype=np.float32)\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "            static_image_mode=True,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5) as face_mesh:\n",
    "        \n",
    "        for i, file in enumerate(files):\n",
    "            print(f\"Elaborazione di {file}\")\n",
    "            image = cv2.imread(f\"data/frames/{file}\")\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Immagine {file} non trovata o non caricata correttamente.\")\n",
    "\n",
    "            # Rileva il volto\n",
    "            with mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
    "                detection_results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                if detection_results.detections:\n",
    "                    bboxC = detection_results.detections[0].location_data.relative_bounding_box\n",
    "                    ih, iw, _ = image.shape\n",
    "                    x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                    margin_w, margin_h = int(0.25 * w), int(0.25 * h)\n",
    "                    x, y = max(0, x - margin_w), max(0, y - margin_h)\n",
    "                    w, h = min(iw, w + 2 * margin_w), min(ih, h + 2 * margin_h)\n",
    "                    face_crop = image[y:y+h, x:x+w]\n",
    "                    image = cv2.resize(face_crop, (256, 256))\n",
    "            \n",
    "            # Ottieni i landmark\n",
    "            results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            if results.multi_face_landmarks:\n",
    "                for idx, landmark in enumerate(results.multi_face_landmarks[0].landmark):\n",
    "                    landmark_tensor[i, idx] = [landmark.x, landmark.y, landmark.z]\n",
    "    \n",
    "    # Usa i canali rosso, verde e blu\n",
    "    rgb_tensor = np.zeros_like(landmark_tensor, dtype=np.uint8)\n",
    "    rgb_tensor[:, :, 0] = landmark_tensor[:, :, 0] * 255  # Rosso\n",
    "    rgb_tensor[:, :, 1] = landmark_tensor[:, :, 1] * 255  # Verde\n",
    "    rgb_tensor[:, :, 2] = landmark_tensor[:, :, 2] * 255  # Blu\n",
    "    \n",
    "    # Plot del tensore come immagine\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(rgb_tensor.reshape(num_frames, 478, 3))  # Visualizza l'immagine\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    #save image\n",
    "    plt.imsave('data/landmarks.jpg', rgb_tensor.reshape(num_frames, 478, 3))\n",
    "\n",
    "process_frames_and_plot()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "JxpgRUeUtfGH",
    "outputId": "a5297913-8168-4d43-f10a-7c435649b0f6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Name tensor",
   "metadata": {
    "id": "i_z7erSKlLbn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def name_tensor(folder):\n",
    "    # Take the name after the first underscore\n",
    "    id_video = os.path.basename(folder).split('_', 1)[1]\n",
    "    \n",
    "    # Navigate to the folder before, e.g., frames → user folder\n",
    "    id_user = folder.split('/')[-3]\n",
    "    \n",
    "    # Read the CSV file\n",
    "    csv_path = f'data/users/{id_user}/{id_user}.csv'\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"⚠️ CSV file not found: {csv_path}\")\n",
    "        return None  # Scarta il tensore\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = df.columns.str.strip()  # Remove spaces in column names\n",
    "    \n",
    "    # Match id_video\n",
    "    row = df.loc[df['Stimulus'].str.strip() == id_video.strip()]\n",
    "    if row.empty:\n",
    "        print(f\"❌ ID video '{id_video}' non trovato nel CSV di {id_user}, tensore scartato.\")\n",
    "        return None  # Scarta il tensore\n",
    "    \n",
    "    arousal = row['Arousal'].values[0]\n",
    "    valence = row['Valence'].values[0]\n",
    "    likeability = row['Likability'].values[0]\n",
    "    rewatch = row['Rewatch'].values[0]\n",
    "    \n",
    "    return f'{id_user}_{id_video}_{arousal}_{valence}_{likeability}_{rewatch}.npy'\n"
   ],
   "metadata": {
    "id": "fQaQl7XStwMO",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "outputId": "07d25933-0620-42c8-8d7e-f64d11ff3f8c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create tensors"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Imposta la libreria MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "# Funzione per estrarre i landmark per ogni frame\n",
    "def extract_landmarks_from_frames(video_folder):\n",
    "    # Ottieni tutti i frame ordinati\n",
    "    files = sorted(os.listdir(video_folder))\n",
    "    num_frames = len(files)\n",
    "    landmark_tensor = np.zeros((num_frames, 478, 3), dtype=np.float32)\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "            static_image_mode=True,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5) as face_mesh:\n",
    "        \n",
    "        for i, file in enumerate(files):\n",
    "            image = cv2.imread(f\"{video_folder}/{file}\")\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Immagine {file} non trovata o non caricata correttamente.\")\n",
    "\n",
    "            # Rileva il volto con Face Detection\n",
    "            with mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
    "                detection_results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                if detection_results.detections:\n",
    "                    bboxC = detection_results.detections[0].location_data.relative_bounding_box\n",
    "                    ih, iw, _ = image.shape\n",
    "                    x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                    margin_w, margin_h = int(0.25 * w), int(0.25 * h)\n",
    "                    x, y = max(0, x - margin_w), max(0, y - margin_h)\n",
    "                    w, h = min(iw, w + 2 * margin_w), min(ih, h + 2 * margin_h)\n",
    "                    face_crop = image[y:y+h, x:x+w]\n",
    "                    image = cv2.resize(face_crop, (256, 256))\n",
    "\n",
    "            # Ottieni i landmark usando FaceMesh\n",
    "            results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            if results.multi_face_landmarks:\n",
    "                for landmarks in results.multi_face_landmarks:\n",
    "                    # Salva i landmarks in landmark_tensor\n",
    "                    for j, landmark in enumerate(landmarks.landmark):\n",
    "                        landmark_tensor[i, j] = [landmark.x, landmark.y, landmark.z]\n",
    "\n",
    "    return landmark_tensor\n",
    "\n",
    "\n",
    "def process_videos():\n",
    "    base_path = 'data/users'\n",
    "\n",
    "    for user in os.listdir(base_path):\n",
    "        user_path = os.path.join(base_path, user)\n",
    "        frames_path = os.path.join(user_path, 'frames')\n",
    "\n",
    "        if not os.path.isdir(frames_path):\n",
    "            continue\n",
    "\n",
    "        for video_folder in os.listdir(frames_path):\n",
    "            video_folder_path = os.path.join(frames_path, video_folder)\n",
    "\n",
    "            if os.path.isdir(video_folder_path):\n",
    "                print(f\"🎬 Elaborazione del video {video_folder} per l'utente {user}\")\n",
    "                \n",
    "                landmark_tensor = extract_landmarks_from_frames(video_folder_path)\n",
    "                \n",
    "                tensor_name = name_tensor(video_folder_path.replace('\\\\', '/'))\n",
    "                if tensor_name is None:\n",
    "                    continue  # Se il tensore è da scartare, passa al prossimo video\n",
    "                \n",
    "                np.save(f\"data/users/{user}/tensors/{tensor_name}\", landmark_tensor)\n",
    "\n",
    "\n",
    "process_videos()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Delete tensors"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "def delete_all_tensors():\n",
    "    base_path = 'data/users'\n",
    "\n",
    "    for root, _, files in os.walk(base_path):  # Scansiona tutte le cartelle e sottocartelle\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):  # Controlla se il file è un tensore\n",
    "                file_path = os.path.join(root, file)\n",
    "                os.remove(file_path)\n",
    "                print(f\"Eliminato: {file_path}\")\n",
    "\n",
    "# Esegui la funzione\n",
    "delete_all_tensors()\n"
   ]
  }
 ]
}
